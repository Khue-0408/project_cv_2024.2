{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-10T01:49:33.043634Z",
     "iopub.status.busy": "2025-04-10T01:49:33.043384Z",
     "iopub.status.idle": "2025-04-10T01:49:33.048471Z",
     "shell.execute_reply": "2025-04-10T01:49:33.047613Z",
     "shell.execute_reply.started": "2025-04-10T01:49:33.043618Z"
    },
    "id": "gLuT269U_m8T",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from torchvision import transforms\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-10T01:49:34.945549Z",
     "iopub.status.busy": "2025-04-10T01:49:34.945086Z",
     "iopub.status.idle": "2025-04-10T01:49:34.952026Z",
     "shell.execute_reply": "2025-04-10T01:49:34.951218Z",
     "shell.execute_reply.started": "2025-04-10T01:49:34.945528Z"
    },
    "id": "wWV2_y3R_m8W",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, img_dir, mask_dir, resize=None, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.resize = resize\n",
    "        self.transform = transform\n",
    "        self.image_files = sorted([f for f in os.listdir(self.img_dir) if f.endswith('.png')])\n",
    "        self.mask_files = sorted([f for f in os.listdir(self.mask_dir) if f.endswith('.png')])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.image_files[idx])\n",
    "        mask_path = os.path.join(self.mask_dir, self.mask_files[idx])\n",
    "\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.resize(image, self.resize)\n",
    "\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        mask = cv2.resize(mask, self.resize)\n",
    "        mask = (mask > 127).astype(np.uint8)  # binary: white -> 1, black -> 0\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image, mask=mask)\n",
    "            image = augmented['image']\n",
    "            mask = augmented['mask'].unsqueeze(0)  # Add channel dimension: (1, H, W)\n",
    "\n",
    "        return image, mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-10T01:49:38.394289Z",
     "iopub.status.busy": "2025-04-10T01:49:38.393721Z",
     "iopub.status.idle": "2025-04-10T01:49:38.404023Z",
     "shell.execute_reply": "2025-04-10T01:49:38.403329Z",
     "shell.execute_reply.started": "2025-04-10T01:49:38.394264Z"
    },
    "id": "qtu-4HlL_m8W",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "from torchvision.models.feature_extraction import create_feature_extractor\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, num_classes=1, pretrained=True):\n",
    "        super(UNet, self).__init__()\n",
    "        resnet = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2 if pretrained else None)\n",
    "        self.encoder = create_feature_extractor(resnet, return_nodes={\n",
    "            \"relu\": \"enc1\",          # (B, 64, H, W)\n",
    "            \"layer1\": \"enc2\",        # (B, 256, H/2, W/2)\n",
    "            \"layer2\": \"enc3\",        # (B, 512, H/4, W/4)\n",
    "            \"layer3\": \"enc4\",        # (B, 1024, H/8, W/8)\n",
    "            \"layer4\": \"bridge\"       # (B, 2048, H/16, W/16)\n",
    "        })\n",
    "        self.decoder4 = DoubleConv(2048 + 1024, 1024)\n",
    "        self.decoder3 = DoubleConv(1024 + 512, 512)\n",
    "        self.decoder2 = DoubleConv(512 + 256, 256)\n",
    "        self.decoder1 = DoubleConv(256 + 64, 64)\n",
    "        self.final_conv = nn.Conv2d(64, num_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.encoder(x)\n",
    "\n",
    "        enc1 = features[\"enc1\"]  # (B, 64, H, W)\n",
    "        enc2 = features[\"enc2\"]  # (B, 256, H/2, W/2)\n",
    "        enc3 = features[\"enc3\"]  # (B, 512, H/4, W/4)\n",
    "        enc4 = features[\"enc4\"]  # (B, 1024, H/8, W/8)\n",
    "        bridge = features[\"bridge\"]  # (B, 2048, H/16, W/16)\n",
    "        dec4 = self.decoder4(torch.cat([F.interpolate(bridge, size=enc4.shape[2:], mode=\"bilinear\", align_corners=True), enc4], dim=1))\n",
    "        dec3 = self.decoder3(torch.cat([F.interpolate(dec4, size=enc3.shape[2:], mode=\"bilinear\", align_corners=True), enc3], dim=1))\n",
    "        dec2 = self.decoder2(torch.cat([F.interpolate(dec3, size=enc2.shape[2:], mode=\"bilinear\", align_corners=True), enc2], dim=1))\n",
    "        dec1 = self.decoder1(torch.cat([F.interpolate(dec2, size=enc1.shape[2:], mode=\"bilinear\", align_corners=True), enc1], dim=1))\n",
    "        output = self.final_conv(dec1)\n",
    "        output = F.interpolate(output, size=x.shape[2:], mode=\"bilinear\", align_corners=True)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "udyaMksM_m8X",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "class StructureLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(StructureLoss, self).__init__()\n",
    "        self.bce = nn.BCEWithLogitsLoss(reduction='none')\n",
    "\n",
    "    def forward(self, pred, mask):\n",
    "        pred = F.interpolate(pred, size=mask.shape[2:], mode='bilinear', align_corners=True)\n",
    "\n",
    "        weit = 1 + 5 * torch.abs(F.avg_pool2d(mask.float(), kernel_size=31, stride=1, padding=15) - mask.float())\n",
    "        bce = self.bce(pred, mask.float())\n",
    "        bce = (weit * bce).sum(dim=(2, 3)) / weit.sum(dim=(2, 3))\n",
    "\n",
    "        pred_probs = torch.sigmoid(pred)\n",
    "        inter = (pred_probs * mask).sum(dim=(2, 3))\n",
    "        union = (pred_probs + mask).sum(dim=(2, 3))\n",
    "        iou = 1 - (inter + 1) / (union - inter + 1)\n",
    "\n",
    "        return (bce + iou).mean()\n",
    "\n",
    "\n",
    "train_transform = A.Compose(\n",
    "    [\n",
    "        A.HorizontalFlip(p=0.4),\n",
    "        A.VerticalFlip(p=0.4),\n",
    "        A.RandomGamma(gamma_limit=(70, 130), p=0.2),\n",
    "        A.RGBShift(p=0.3, r_shift_limit=10, g_shift_limit=10, b_shift_limit=10),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        ToTensorV2(),\n",
    "    ],\n",
    "    additional_targets={'mask': 'mask'}  # Tells Albumentations to treat mask separately\n",
    ")\n",
    "\n",
    "lr = 3e-4\n",
    "batch_size = 8\n",
    "epochs = 300\n",
    "in_channels = 3\n",
    "out_channels = 1\n",
    "H, W = 480, 480\n",
    "\n",
    "model = UNet(num_classes=out_channels)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "loss_fn = StructureLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.75, patience=5)\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "train_dataset = CustomDataset(\n",
    "    img_dir='/kaggle/input/datacv/TrainDataset/TrainDataset/image',\n",
    "    mask_dir='/kaggle/input/datacv/TrainDataset/TrainDataset/mask',\n",
    "    resize=(H, W),\n",
    "    transform=train_transform,\n",
    ")\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "best_loss = float('inf')  # Initialize best loss\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{epochs}\", leave=False)\n",
    "\n",
    "    for images, masks in progress_bar:\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device).float()  # Ensure shape [B, 1, H, W] and float\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = loss_fn(outputs, masks)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "    epoch_loss /= len(train_loader)\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    # Save model if current loss is lower than best\n",
    "    if epoch_loss < best_loss:\n",
    "        best_loss = epoch_loss\n",
    "        torch.save(model.state_dict(), 'Unet.pth')\n",
    "        print(f\"âœ… Saved new best model at epoch {epoch + 1} with loss {best_loss:.4f}\")\n",
    "\n",
    "    scheduler.step(epoch_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gO7oY79P_m8Y",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"/kaggle/working/Unet_last.pth\")\n",
    "print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3-WLaPb2_m8Y",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "device = 'cuda'\n",
    "def infer(model, image_path, device, threshold=0.5):\n",
    "    model.eval()\n",
    "\n",
    "    # Load and preprocess image\n",
    "    image = cv2.imread(image_path)\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    transformed = A.Compose([\n",
    "        A.Resize(480, 480),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        ToTensorV2(),\n",
    "    ])(image=image_rgb)\n",
    "\n",
    "    input_tensor = transformed['image'].unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_tensor)\n",
    "\n",
    "        if isinstance(outputs, tuple):\n",
    "            main_output = outputs[0]\n",
    "        else:\n",
    "            main_output = outputs\n",
    "\n",
    "        # Binary output: apply sigmoid and threshold\n",
    "        prob_mask = torch.sigmoid(main_output).squeeze().cpu().numpy()\n",
    "        binary_mask = (prob_mask > threshold).astype(np.uint8) * 255  # foreground=255, background=0\n",
    "\n",
    "    # Show results\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image_rgb)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(binary_mask, cmap=\"gray\")\n",
    "    plt.title(\"Predicted Mask (Binary)\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "model = UNet(num_classes=1).to(device)\n",
    "model.load_state_dict(torch.load(\"/kaggle/working/Unet.pth\", map_location=device))\n",
    "model.eval()\n",
    "infer(model, \"/kaggle/input/datacv/TrainDataset/TrainDataset/image/10.png\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-10T01:51:54.506444Z",
     "iopub.status.busy": "2025-04-10T01:51:54.505974Z",
     "iopub.status.idle": "2025-04-10T01:52:02.072487Z",
     "shell.execute_reply": "2025-04-10T01:52:02.071607Z",
     "shell.execute_reply.started": "2025-04-10T01:51:54.506421Z"
    },
    "id": "ekSk8yuL_m8Z",
    "outputId": "d9f7b86e-df45-4d52-822d-ec41023a1f36",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_79/3404380625.py:24: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"/kaggle/input/comvsdataprime/Unet.pth\", map_location='cuda' if torch.cuda.is_available() else 'cpu'))\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:06<00:00, 16.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Macro IoU: 0.8152\n",
      "ðŸ“Š Macro Dice: 0.8746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# Assuming you already have UNet and CustomDataset defined\n",
    "val_transform = A.Compose([\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "# Load test dataset\n",
    "test_dataset = CustomDataset(\n",
    "    img_dir='/kaggle/input/comvsdataprime/TestDataset/TestDataset/Kvasir/images',\n",
    "    mask_dir='/kaggle/input/comvsdataprime/TestDataset/TestDataset/Kvasir/masks',\n",
    "    resize=(480, 480),\n",
    "    transform=val_transform,  # no strong augmentations\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Load trained model\n",
    "model = UNet(num_classes=1)\n",
    "model.load_state_dict(torch.load(\"/kaggle/input/comvsdataprime/Unet.pth\", map_location='cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Helper functions\n",
    "def compute_iou(pred, mask, eps=1e-6):\n",
    "    pred = (pred > 0.5).float()\n",
    "    mask = (mask > 0.5).float()\n",
    "    intersection = (pred * mask).sum()\n",
    "    union = pred.sum() + mask.sum() - intersection\n",
    "    return (intersection + eps) / (union + eps)\n",
    "\n",
    "def compute_dice(pred, mask, eps=1e-6):\n",
    "    pred = (pred > 0.5).float()\n",
    "    mask = (mask > 0.5).float()\n",
    "    intersection = (pred * mask).sum()\n",
    "    return (2 * intersection + eps) / (pred.sum() + mask.sum() + eps)\n",
    "\n",
    "# Run evaluation\n",
    "ious, dices = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, masks in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device).float()\n",
    "\n",
    "        outputs = model(images)\n",
    "        probs = torch.sigmoid(outputs)\n",
    "\n",
    "        for pred, true_mask in zip(probs, masks):\n",
    "            iou = compute_iou(pred, true_mask)\n",
    "            dice = compute_dice(pred, true_mask)\n",
    "            ious.append(iou.item())\n",
    "            dices.append(dice.item())\n",
    "\n",
    "macro_iou = np.mean(ious)\n",
    "macro_dice = np.mean(dices)\n",
    "\n",
    "print(f\"ðŸ“Š Macro IoU: {macro_iou:.4f}\")\n",
    "print(f\"ðŸ“Š Macro Dice: {macro_dice:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-10T01:53:58.989798Z",
     "iopub.status.busy": "2025-04-10T01:53:58.989298Z",
     "iopub.status.idle": "2025-04-10T01:54:44.717952Z",
     "shell.execute_reply": "2025-04-10T01:54:44.717135Z",
     "shell.execute_reply.started": "2025-04-10T01:53:58.989775Z"
    },
    "id": "IY48bYxu_m8Z",
    "outputId": "a40bfc18-627f-4e40-c70b-f91f74c7364a",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_79/2925089652.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"/kaggle/input/comvsdataprime/Unet.pth\", map_location='cuda' if torch.cuda.is_available() else 'cpu'))\n",
      "Evaluating all datasets: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [00:44<00:00, 17.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Macro IoU (All datasets): 0.6403\n",
      "ðŸ“Š Macro Dice (All datasets): 0.7051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import cv2\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# CustomDataset class (as you already defined)\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, img_dir, mask_dir, resize=None, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.resize = resize\n",
    "        self.transform = transform\n",
    "        self.image_files = sorted([f for f in os.listdir(self.img_dir) if f.endswith('.png')])\n",
    "        self.mask_files = sorted([f for f in os.listdir(self.mask_dir) if f.endswith('.png')])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.image_files[idx])\n",
    "        mask_path = os.path.join(self.mask_dir, self.mask_files[idx])\n",
    "\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.resize(image, self.resize)\n",
    "\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        mask = cv2.resize(mask, self.resize)\n",
    "        mask = (mask > 127).astype(np.uint8)\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image, mask=mask)\n",
    "            image = augmented['image']\n",
    "            mask = augmented['mask'].unsqueeze(0)  # shape: (1, H, W)\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "# Define transforms\n",
    "val_transform = A.Compose([\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "# List of dataset subfolders\n",
    "dataset_names = ['CVC-300', 'CVC-ClinicDB', 'CVC-ColonDB', 'ETIS-LaribPolypDB', 'Kvasir']\n",
    "base_path = '/kaggle/input/comvsdataprime/TestDataset/TestDataset'\n",
    "\n",
    "# Collect all datasets\n",
    "all_datasets = []\n",
    "for name in dataset_names:\n",
    "    img_dir = os.path.join(base_path, name, 'images')\n",
    "    mask_dir = os.path.join(base_path, name, 'masks')\n",
    "    ds = CustomDataset(img_dir=img_dir, mask_dir=mask_dir, resize=(480, 480), transform=val_transform)\n",
    "    all_datasets.append(ds)\n",
    "\n",
    "# Combine datasets\n",
    "full_test_dataset = ConcatDataset(all_datasets)\n",
    "test_loader = DataLoader(full_test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Load model\n",
    "model = UNet(num_classes=1)\n",
    "model.load_state_dict(torch.load(\"/kaggle/input/comvsdataprime/Unet.pth\", map_location='cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Metrics\n",
    "def compute_iou(pred, mask, eps=1e-6):\n",
    "    pred = (pred > 0.5).float()\n",
    "    mask = (mask > 0.5).float()\n",
    "    intersection = (pred * mask).sum()\n",
    "    union = pred.sum() + mask.sum() - intersection\n",
    "    return (intersection + eps) / (union + eps)\n",
    "\n",
    "def compute_dice(pred, mask, eps=1e-6):\n",
    "    pred = (pred > 0.5).float()\n",
    "    mask = (mask > 0.5).float()\n",
    "    intersection = (pred * mask).sum()\n",
    "    return (2 * intersection + eps) / (pred.sum() + mask.sum() + eps)\n",
    "\n",
    "# Run evaluation\n",
    "ious, dices = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, masks in tqdm(test_loader, desc=\"Evaluating all datasets\"):\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device).float()\n",
    "\n",
    "        outputs = model(images)\n",
    "        probs = torch.sigmoid(outputs)\n",
    "\n",
    "        for pred, true_mask in zip(probs, masks):\n",
    "            iou = compute_iou(pred, true_mask)\n",
    "            dice = compute_dice(pred, true_mask)\n",
    "            ious.append(iou.item())\n",
    "            dices.append(dice.item())\n",
    "\n",
    "# Final results\n",
    "macro_iou = np.mean(ious)\n",
    "macro_dice = np.mean(dices)\n",
    "\n",
    "print(f\"ðŸ“Š Macro IoU (All datasets): {macro_iou:.4f}\")\n",
    "print(f\"ðŸ“Š Macro Dice (All datasets): {macro_dice:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7097167,
     "sourceId": 11343386,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
