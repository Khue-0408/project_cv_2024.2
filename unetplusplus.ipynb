{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11343386,"sourceType":"datasetVersion","datasetId":7097167}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport os\nimport pandas as pd\nimport numpy as np\nimport cv2\nfrom torch.utils.data import Dataset, DataLoader\nimport albumentations as A\nfrom albumentations.pytorch.transforms import ToTensorV2\nfrom torchvision import transforms\nfrom torch.optim import Adam\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-10T01:59:22.746714Z","iopub.execute_input":"2025-04-10T01:59:22.747031Z","iopub.status.idle":"2025-04-10T01:59:22.751752Z","shell.execute_reply.started":"2025-04-10T01:59:22.747008Z","shell.execute_reply":"2025-04-10T01:59:22.750795Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"\nclass CustomDataset(Dataset):\n    def __init__(self, img_dir, mask_dir, resize=(480, 480), transform=None):\n        self.img_dir = img_dir\n        self.mask_dir = mask_dir\n        self.resize = resize\n        self.transform = transform\n        self.image_files = sorted([f for f in os.listdir(self.img_dir) if f.endswith('.png')])\n        self.mask_files = sorted([f for f in os.listdir(self.mask_dir) if f.endswith('.png')])\n\n    def __len__(self):\n        return len(self.image_files)\n\n    def __getitem__(self, idx):\n        img_path = os.path.join(self.img_dir, self.image_files[idx])\n        mask_path = os.path.join(self.mask_dir, self.mask_files[idx])\n\n        image = cv2.imread(img_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        image = cv2.resize(image, self.resize)\n\n        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n        mask = cv2.resize(mask, self.resize)\n        mask = (mask > 127).astype(np.uint8)  # binary: white -> 1, black -> 0\n\n        if self.transform:\n            augmented = self.transform(image=image, mask=mask)\n            image = augmented['image']\n            mask = augmented['mask'].unsqueeze(0)  # Add channel dimension: (1, H, W)\n\n        return image, mask","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T01:59:24.345294Z","iopub.execute_input":"2025-04-10T01:59:24.345630Z","iopub.status.idle":"2025-04-10T01:59:24.352626Z","shell.execute_reply.started":"2025-04-10T01:59:24.345588Z","shell.execute_reply":"2025-04-10T01:59:24.351422Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import models\n\nclass ConvBlock(nn.Module):\n    \"\"\"\n    A basic convolution block: Conv2d -> BatchNorm -> ReLU.\n    \"\"\"\n    def __init__(self, in_channels, out_channels):\n        super(ConvBlock, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n        self.bn   = nn.BatchNorm2d(out_channels)\n        self.relu = nn.ReLU(inplace=True)\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.bn(x)\n        x = self.relu(x)\n        return x\nclass UNetPlusPlus(nn.Module):\n    def __init__(self, num_classes=1, H=480, W=480, deep_supervision=True):\n        super(UNetPlusPlus, self).__init__()\n        self.H = H\n        self.W = W\n        self.deep_supervision = deep_supervision\n        resnet = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n\n        # Encoder (same as before)\n        self.x00 = nn.Sequential(resnet.conv1, resnet.bn1, resnet.relu, resnet.maxpool)\n        self.x10 = resnet.layer1\n        self.x20 = resnet.layer2\n        self.x30 = resnet.layer3\n        self.x40 = resnet.layer4\n        self.upsample = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=True)\n\n        # Decoder (same as before)\n        self.conv01 = ConvBlock(64 + 256, 64)\n        self.conv11 = ConvBlock(256 + 512, 256)\n        self.conv21 = ConvBlock(512 + 1024, 512)\n        self.conv31 = ConvBlock(1024 + 2048, 1024)\n\n        self.conv02 = ConvBlock(64 + 64 + 256, 64)\n        self.conv12 = ConvBlock(256 + 256 + 512, 256)\n        self.conv22 = ConvBlock(512 + 512 + 1024, 512)\n\n        self.conv03 = ConvBlock(64 + 64 + 64 + 256, 64)\n        self.conv13 = ConvBlock(256 + 256 + 256 + 512, 256)\n\n        self.conv04 = ConvBlock(64 + 64 + 64 + 64 + 256, 64)\n\n        # Final prediction layers (deep supervision heads)\n        self.final_1 = nn.Conv2d(64, num_classes, kernel_size=1)\n        self.final_2 = nn.Conv2d(64, num_classes, kernel_size=1)\n        self.final_3 = nn.Conv2d(64, num_classes, kernel_size=1)\n        self.final_4 = nn.Conv2d(64, num_classes, kernel_size=1)\n\n    def forward(self, x):\n        x00 = self.x00(x)\n        x10 = self.x10(x00)\n        x20 = self.x20(x10)\n        x30 = self.x30(x20)\n        x40 = self.x40(x30)\n\n        x01 = self.conv01(torch.cat([x00, x10], dim=1))\n        x11 = self.conv11(torch.cat([x10, self.upsample(x20)], dim=1))\n        x21 = self.conv21(torch.cat([x20, self.upsample(x30)], dim=1))\n        x31 = self.conv31(torch.cat([x30, self.upsample(x40)], dim=1))\n\n        x02 = self.conv02(torch.cat([x00, x01, x11], dim=1))\n        x12 = self.conv12(torch.cat([x10, x11, self.upsample(x21)], dim=1))\n        x22 = self.conv22(torch.cat([x20, x21, self.upsample(x31)], dim=1))\n\n        x03 = self.conv03(torch.cat([x00, x01, x02, x12], dim=1))\n        x13 = self.conv13(torch.cat([x10, x11, x12, self.upsample(x22)], dim=1))\n\n        x04 = self.conv04(torch.cat([x00, x01, x02, x03, x13], dim=1))\n\n        # Deep supervision outputs\n        out1 = F.interpolate(self.final_1(x01), size=(self.H, self.W), mode=\"bilinear\", align_corners=True)\n        out2 = F.interpolate(self.final_2(x02), size=(self.H, self.W), mode=\"bilinear\", align_corners=True)\n        out3 = F.interpolate(self.final_3(x03), size=(self.H, self.W), mode=\"bilinear\", align_corners=True)\n        out4 = F.interpolate(self.final_4(x04), size=(self.H, self.W), mode=\"bilinear\", align_corners=True)\n\n        if self.deep_supervision:\n            return [out1, out2, out3, out4]\n        else:\n            return out4  # final only\n\n\nclass StructureLoss(nn.Module):\n    def __init__(self):\n        super(StructureLoss, self).__init__()\n        self.bce = nn.BCEWithLogitsLoss(reduction='none')\n\n    def forward(self, pred, mask):\n        pred = F.interpolate(pred, size=mask.shape[2:], mode='bilinear', align_corners=True)\n\n        weit = 1 + 5 * torch.abs(F.avg_pool2d(mask.float(), kernel_size=31, stride=1, padding=15) - mask.float())\n        bce = self.bce(pred, mask.float())\n        bce = (weit * bce).sum(dim=(2, 3)) / weit.sum(dim=(2, 3))\n\n        pred_probs = torch.sigmoid(pred)\n        inter = (pred_probs * mask).sum(dim=(2, 3))\n        union = (pred_probs + mask).sum(dim=(2, 3))\n        iou = 1 - (inter + 1) / (union - inter + 1)\n\n        return (bce + iou).mean()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T01:59:27.113376Z","iopub.execute_input":"2025-04-10T01:59:27.113730Z","iopub.status.idle":"2025-04-10T01:59:27.130840Z","shell.execute_reply.started":"2025-04-10T01:59:27.113700Z","shell.execute_reply":"2025-04-10T01:59:27.129999Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom tqdm import tqdm\nimport os\nimport cv2\nimport numpy as np\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\n\ntrain_transform = A.Compose([\n    A.HorizontalFlip(p=0.4),\n    A.VerticalFlip(p=0.4),\n    A.RandomGamma(gamma_limit=(70, 130), p=0.2),\n    A.RGBShift(p=0.3, r_shift_limit=10, g_shift_limit=10, b_shift_limit=10),\n    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n    ToTensorV2(),\n])\nimg_dir = \"/kaggle/input/datacv/drive-download-20250407T081859Z-001/TrainDataset/TrainDataset/image\"  # update this\nmask_dir = \"/kaggle/input/datacv/drive-download-20250407T081859Z-001/TrainDataset/TrainDataset/mask\"\n# === Parameters ===\nlr = 3e-4\nbatch_size = 16\nin_channels = 3\nout_channels = 1\nH, W = 480, 480\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ntrain_dataset = CustomDataset(img_dir=img_dir, mask_dir=mask_dir, transform=train_transform)\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n\n# === Phase 1: Train without deep supervision ===\nmodel = UNetPlusPlus(num_classes=out_channels, H=H, W=W, deep_supervision=False)\nmodel.to(device)\n\nloss_fn = StructureLoss()\noptimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\nscheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.75, patience=5)\nscaler = torch.cuda.amp.GradScaler()\n\nfor epoch in range(150):\n    model.train()\n    epoch_loss = 0.0\n    progress_bar = tqdm(train_loader, desc=f\"Phase 1 - Epoch {epoch+1}/100\", leave=False)\n\n    for images, masks in progress_bar:\n        images = images.to(device, non_blocking=True)\n        masks = masks.to(device, non_blocking=True)\n\n        optimizer.zero_grad()\n        with torch.cuda.amp.autocast():\n            outputs = model(images)\n            loss = loss_fn(outputs, masks)\n\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n\n        epoch_loss += loss.item()\n        progress_bar.set_postfix(loss=loss.item())\n\n    epoch_loss /= len(train_loader)\n    print(f\"[Phase 1] Epoch {epoch+1}/100 | Loss: {epoch_loss:.4f}\")\n    if (epoch + 1) % 15 == 0:\n        torch.save(model.state_dict(), f\"/kaggle/working/model_phase1_epoch{epoch+1}.pth\")\n    scheduler.step(epoch_loss)\n\n# === Save final Phase 1 weights ===\ntorch.save(model.state_dict(), \"/kaggle/working/model_phase1_final.pth\")\n\n# === Phase 2: Load weights and train with deep supervision ===\nmodel = UNetPlusPlus(num_classes=out_channels, H=H, W=W, deep_supervision=True)\nmodel.load_state_dict(torch.load(\"/kaggle/working/model_phase1_final.pth\"))\nmodel.to(device)\n\noptimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)  # lower LR\nscheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.75, patience=5)\nscaler = torch.cuda.amp.GradScaler()\n\nfor epoch in range(151, 201):\n    model.train()\n    epoch_loss = 0.0\n    progress_bar = tqdm(train_loader, desc=f\"Phase 2 - Epoch {epoch}/150\", leave=False)\n\n    for images, masks in progress_bar:\n        images = images.to(device, non_blocking=True)\n        masks = masks.to(device, non_blocking=True)\n\n        optimizer.zero_grad()\n        with torch.cuda.amp.autocast():\n            outputs = model(images)\n            if isinstance(outputs, list):\n                # Weighted deep supervision loss\n                weights = [0.1, 0.2, 0.3, 0.4]\n                loss = sum(w * loss_fn(o, masks) for w, o in zip(weights, outputs))\n            else:\n                loss = loss_fn(outputs, masks)\n\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n\n        epoch_loss += loss.item()\n        progress_bar.set_postfix(loss=loss.item())\n\n    epoch_loss /= len(train_loader)\n    print(f\"[Phase 2] Epoch {epoch}/150 | Loss: {epoch_loss:.4f}\")\n    if epoch % 10 == 0:\n        torch.save(model.state_dict(), f\"/kaggle/working/model_phase2_epoch{epoch}.pth\")\n    scheduler.step(epoch_loss)\n\n# === Save final Phase 2 weights ===\ntorch.save(model.state_dict(), \"/kaggle/working/model_phase2_final.pth\")\n ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T18:07:42.303885Z","iopub.execute_input":"2025-04-08T18:07:42.304185Z","iopub.status.idle":"2025-04-08T18:36:59.276853Z","shell.execute_reply.started":"2025-04-08T18:07:42.304165Z","shell.execute_reply":"2025-04-08T18:36:59.276013Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.save(model.state_dict(), \"/kaggle/working/model_weights.pth\")   ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\ndevice = 'cuda'\n\ndef infer(model, image_path, device):\n    model.eval()\n    image = cv2.imread(image_path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    \n    transformed = A.Compose([\n        A.Resize(480, 480),\n        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n        ToTensorV2(),\n    ])(image=image)\n    \n    input_tensor = transformed['image'].unsqueeze(0).to(device)\n    \n    with torch.no_grad():\n        output = model(input_tensor)\n        if isinstance(output, (list, tuple)):\n            output = output[-1]\n        output = torch.sigmoid(output)\n        prediction = (output > 0.5).float().squeeze().cpu().numpy()\n\n    binary_mask = (prediction * 255).astype(np.uint8)  # 0 for background, 255 for object\n\n    plt.figure(figsize=(10, 5))\n    plt.subplot(1, 2, 1)\n    plt.imshow(image)\n    plt.title(\"Original Image\")\n    plt.axis(\"off\")\n    \n    plt.subplot(1, 2, 2)\n    plt.imshow(binary_mask, cmap=\"gray\")\n    plt.title(\"Binary Mask\")\n    plt.axis(\"off\")\n    plt.show() \nmodel = UNetPlusPlus(num_classes=1, deep_supervision=False).to(device) \nmodel.load_state_dict(torch.load(\"/kaggle/working/model_weights.pth\", map_location=device))\nmodel.eval()\ninfer(model, \"/kaggle/input/datacv/drive-download-20250407T081859Z-001/TrainDataset/TrainDataset/image/1.png\", device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T18:40:36.701200Z","iopub.execute_input":"2025-04-08T18:40:36.701517Z","iopub.status.idle":"2025-04-08T18:40:38.177238Z","shell.execute_reply.started":"2025-04-08T18:40:36.701491Z","shell.execute_reply":"2025-04-08T18:40:38.176365Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader\nimport numpy as np\nfrom tqdm import tqdm\nimport os\n\n# Assuming you already have UNet and CustomDataset defined\nval_transform = A.Compose([\n    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n    ToTensorV2(),\n])\n# Load test dataset\ntest_dataset = CustomDataset(\n    img_dir='/kaggle/input/comvsdataprime/TestDataset/TestDataset/Kvasir/images',\n    mask_dir='/kaggle/input/comvsdataprime/TestDataset/TestDataset/Kvasir/masks',\n    resize=(480, 480),\n    transform=val_transform,  # no strong augmentations\n)\n\ntest_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n\n# Load trained model\nmodel = UNetPlusPlus(num_classes=1, deep_supervision=False)\nmodel.load_state_dict(torch.load(\"/kaggle/input/comvsdataprime/UnetPlusPlus-phase2.pth\", map_location='cuda' if torch.cuda.is_available() else 'cpu'))\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\nmodel.eval()\n\n# Helper functions\ndef compute_iou(pred, mask, eps=1e-6):\n    pred = (pred > 0.5).float()\n    mask = (mask > 0.5).float()\n    intersection = (pred * mask).sum()\n    union = pred.sum() + mask.sum() - intersection\n    return (intersection + eps) / (union + eps)\n\ndef compute_dice(pred, mask, eps=1e-6):\n    pred = (pred > 0.5).float()\n    mask = (mask > 0.5).float()\n    intersection = (pred * mask).sum()\n    return (2 * intersection + eps) / (pred.sum() + mask.sum() + eps)\n\n# Run evaluation\nious, dices = [], []\n\nwith torch.no_grad():\n    for images, masks in tqdm(test_loader, desc=\"Evaluating\"):\n        images = images.to(device)\n        masks = masks.to(device).float()\n\n        outputs = model(images)\n        probs = torch.sigmoid(outputs)\n\n        for pred, true_mask in zip(probs, masks):\n            iou = compute_iou(pred, true_mask)\n            dice = compute_dice(pred, true_mask)\n            ious.append(iou.item())\n            dices.append(dice.item())\n\nmacro_iou = np.mean(ious)\nmacro_dice = np.mean(dices)\n\nprint(f\"ðŸ“Š Macro IoU: {macro_iou:.4f}\")\nprint(f\"ðŸ“Š Macro Dice: {macro_dice:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T02:06:11.738960Z","iopub.execute_input":"2025-04-10T02:06:11.739265Z","iopub.status.idle":"2025-04-10T02:06:20.300012Z","shell.execute_reply.started":"2025-04-10T02:06:11.739243Z","shell.execute_reply":"2025-04-10T02:06:20.299277Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-18-bf23e32e2035>:24: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(\"/kaggle/input/comvsdataprime/UnetPlusPlus-phase2.pth\", map_location='cuda' if torch.cuda.is_available() else 'cpu'))\nEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:07<00:00, 13.73it/s]","output_type":"stream"},{"name":"stdout","text":"ðŸ“Š Macro IoU: 0.8212\nðŸ“Š Macro Dice: 0.8748\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader, ConcatDataset\nimport numpy as np\nfrom tqdm import tqdm\nimport os\nimport cv2\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom torch.utils.data import Dataset\n\n# CustomDataset class (as you already defined)\n\n# Define transforms\nval_transform = A.Compose([\n    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n    ToTensorV2(),\n])\n\n# List of dataset subfolders\ndataset_names = ['CVC-300', 'CVC-ClinicDB', 'CVC-ColonDB', 'ETIS-LaribPolypDB', 'Kvasir']\nbase_path = '/kaggle/input/comvsdataprime/TestDataset/TestDataset'\n\n# Collect all datasets\nall_datasets = []\nfor name in dataset_names:\n    img_dir = os.path.join(base_path, name, 'images')\n    mask_dir = os.path.join(base_path, name, 'masks')\n    ds = CustomDataset(img_dir=img_dir, mask_dir=mask_dir, resize=(480, 480), transform=val_transform)\n    all_datasets.append(ds)\n\n# Combine datasets\nfull_test_dataset = ConcatDataset(all_datasets)\ntest_loader = DataLoader(full_test_dataset, batch_size=1, shuffle=False)\n\n# Load model\nmodel = UNetPlusPlus(num_classes=1, deep_supervision=False)\nmodel.load_state_dict(torch.load(\"/kaggle/input/comvsdataprime/UnetPlusPlus-phase2.pth\", map_location='cuda' if torch.cuda.is_available() else 'cpu'))\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\nmodel.eval()\n\n# Metrics\ndef compute_iou(pred, mask, eps=1e-6):\n    pred = (pred > 0.5).float()\n    mask = (mask > 0.5).float()\n    intersection = (pred * mask).sum()\n    union = pred.sum() + mask.sum() - intersection\n    return (intersection + eps) / (union + eps)\n\ndef compute_dice(pred, mask, eps=1e-6):\n    pred = (pred > 0.5).float()\n    mask = (mask > 0.5).float()\n    intersection = (pred * mask).sum()\n    return (2 * intersection + eps) / (pred.sum() + mask.sum() + eps)\n\n# Run evaluation\nious, dices = [], []\n\nwith torch.no_grad():\n    for images, masks in tqdm(test_loader, desc=\"Evaluating all datasets\"):\n        images = images.to(device)\n        masks = masks.to(device).float()\n\n        outputs = model(images)\n        probs = torch.sigmoid(outputs)\n\n        for pred, true_mask in zip(probs, masks):\n            iou = compute_iou(pred, true_mask)\n            dice = compute_dice(pred, true_mask)\n            ious.append(iou.item())\n            dices.append(dice.item())\n\n# Final results\nmacro_iou = np.mean(ious)\nmacro_dice = np.mean(dices)\n\nprint(f\"ðŸ“Š Macro IoU (All datasets): {macro_iou:.4f}\")\nprint(f\"ðŸ“Š Macro Dice (All datasets): {macro_dice:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T02:07:29.350179Z","iopub.execute_input":"2025-04-10T02:07:29.350469Z","iopub.status.idle":"2025-04-10T02:08:26.533688Z","shell.execute_reply.started":"2025-04-10T02:07:29.350447Z","shell.execute_reply":"2025-04-10T02:08:26.532822Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-19-d27dfd7ccdda>:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(\"/kaggle/input/comvsdataprime/UnetPlusPlus-phase2.pth\", map_location='cuda' if torch.cuda.is_available() else 'cpu'))\nEvaluating all datasets: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 798/798 [00:55<00:00, 14.27it/s]","output_type":"stream"},{"name":"stdout","text":"ðŸ“Š Macro IoU (All datasets): 0.5969\nðŸ“Š Macro Dice (All datasets): 0.6507\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":19}]}